---
title: "How to fix OpenClaw JSON Mode parsing errors with DeepSeek R1"
description: "OpenClaw fails to parse JSON responses from DeepSeek R1. Learn why the thinking tags break JSON mode and how to fix it with a simple system prompt adjustment."
date: "2026-02-03"
author: "LazyDev"
tags: ["DeepSeek", "OpenClaw", "JSON", "Troubleshooting", "R1"]
category: "Troubleshooting"
featured: false
seoKeywords: ["OpenClaw JSON error", "DeepSeek R1 JSON mode", "OpenClaw parsing failed", "DeepSeek thinking tags"]
---

> **TL;DR: The Fix**
>
> DeepSeek R1 wraps responses in `<think>` tags before the actual JSON. OpenClaw's JSON parser fails when it encounters these tags.
>
> **Quick Fix:** Add this to your OpenClaw system prompt:
>
> ```python
> system_prompt = """You are a JSON-only API. Output valid JSON directly.
> Do NOT use <think> tags. Do NOT include any text before or after the JSON.
> Format: {"key": "value"}"""
>
> ollama run deepseek-r1:latest --system "$system_prompt"
> ```

---

## What You're Seeing

When you run OpenClaw with DeepSeek R1 in JSON mode, you get errors like:

```bash
Error: JSON parsing failed
Expecting value: line 1 column 1 (char 0)
  at JSON.parse (<anonymous>)
  at OpenClawResponse.processResponse (/lib/processor.js:42)

Full Response:


{"result": "actual data here"}
```

The actual JSON is valid, but OpenClaw can't parse it because of the `<think>` tags surrounding it.

---

## Root Cause: DeepSeek's Thinking Tags

DeepSeek R1 uses "thinking tags" (`<think>...</think>`) to show its reasoning process before the final answer. This is great for chat, but breaks OpenClaw's JSON parser.

**What's Happening:**
1. DeepSeek generates: `<think>reasoning</think>{"json": "data"}`
2. OpenClaw receives the full response
3. JSON.parse() fails at the first `<` character
4. Request fails with parsing error

**Common Pattern:** This behavior is consistent across DeepSeek R1 variants (8b, 32b, 70b) when JSON mode is expected.

---

## The Fix: System Prompt Override

You have two options:

### Option 1: Disable Thinking Tags (Recommended)

Override the default system prompt to explicitly disable thinking:

```bash
ollama run deepseek-r1:latest \
  --system "You are a JSON API. Output ONLY valid JSON. No thinking tags, no markdown code blocks, no explanations. Just the JSON." \
  --prompt 'Generate {"status": "ok"}'
```

### Option 2: Pre-Process the Response

If you can't change the system prompt, strip the thinking tags before parsing:

```python
import re

def extract_json_from_deepseek(response: str) -> str:
    """
    Extract JSON from DeepSeek R1 response,
    removing <think> tags if present.
    """
    # Remove thinking tags
    cleaned = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)

    # Extract JSON from markdown code blocks if present
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', cleaned, flags=re.DOTALL)
    if json_match:
        return json_match.group(1)

    # Return cleaned response
    return cleaned.strip()

# Usage
raw_response = "<think>reasoning</think>{\"result\": \"data\"}"
json_str = extract_json_from_deepseek(raw_response)
data = json.loads(json_str)
```

---

## When This Happens

JSON parsing errors commonly occur in these scenarios:

| Scenario | Trigger | Fix |
|----------|---------|-----|
| API Mode | OpenClaw expects JSON API responses | Add system prompt override |
| Structured Output | Using OpenClaw's structured output feature | Use Option 2 (pre-process) |
| Tool Calling | DeepSkip is configured for function calling | Disable thinking tags in config |

**Pattern Observed:** This error appears most frequently when:
- First time using DeepSeek R1 with OpenClaw
- After updating DeepSeek R1 model (thinking behavior changed)
- When switching from another model that doesn't use thinking tags

---

## Context Window Truncation (A Related Issue)

Sometimes the JSON appears "cut off" mid-response. This is typically a context window issue:

**Symptoms:**
```json
{"result": "partial data", "status":
```
(response ends abruptly)

**Root Cause:** DeepSeek R1 hit its context limit mid-generation.

**The Fix:**

1. **Reduce Context Window Usage:**
   ```bash
   ollama run deepseek-r1:latest \
     --num_ctx 8192 \
     --repeat-penalty 0.6
   ```

2. **For Production Stability:**

   If you're consistently hitting context limits, consider upgrading to **High-Performance VPS Setup** with more VRAM. Local GPUs with limited VRAM (8GB or less) struggle with larger DeepSeek models.

---

## Complete Working Example

Here's a complete OpenClaw config that works with DeepSeek R1 JSON mode:

```python
# openclaw_config.py
from openclaw import Client

client = Client(model="deepseek-r1:latest")

# Override system prompt to disable thinking tags
client.system_prompt = """You are a JSON-only API.
Rules:
1. Output ONLY valid JSON
2. No <think> tags
3. No markdown code blocks
4. No explanations before/after JSON

Format: {"key": "value"}"""

# Now JSON responses will parse correctly
response = client.generate("Return {'status': 'ok', 'message': 'test'}")
print(response.parsed_json)  # Works!
```

---

## FAQ

<div itemScope itemType="https://schema.org/FAQPage">
  <div itemScope itemType="https://schema.org/Question" itemProp="mainEntity">
    <h3 itemProp="name">Q: Will this fix work with all DeepSeek R1 versions?</h3>
    <div itemScope itemType="https://schema.org/Answer" itemProp="acceptedAnswer">
      <p itemProp="text">
        <strong>A:</strong> Yes. The thinking tags behavior is consistent across DeepSeek R1 variants (8b, 32b, 70b, distilled versions). The system prompt override works for all of them.
      </p>
    </div>
  </div>

  <div itemScope itemType="https://schema.org/Question" itemProp="mainEntity">
    <h3 itemProp="name">Q: Do I need to reinstall DeepSeek R1?</h3>
    <div itemScope itemType="https://schema.org/Answer" itemProp="acceptedAnswer">
      <p itemProp="text">
        <strong>A:</strong> No. This is a configuration issue, not a model issue. The fix is applied at runtime through the system prompt. Your DeepSeek R1 installation is fine.
      </p>
    </div>
  </div>

  <div itemScope itemType="https://schema.org/Question" itemProp="mainEntity">
    <h3 itemProp="name">Q: Can I use this with other models like Llama 3?</h3>
    <div itemScope itemType="https://schema.org/Answer" itemProp="acceptedAnswer">
      <p itemProp="text">
        <strong>A:</strong> Yes. The system prompt override works with any model. However, the thinking tags issue is specific to DeepSeek R1. Other models (Llama, Mistral, etc.) don't use thinking tags by default.
      </p>
    </div>
  </div>
</div>

---

## Related Fixes

- [CVE-2026-25253: OpenClaw RCE Vulnerability Guide](/guides/openclaw-security-rce-cve-2026-25253) - Security considerations for production deployments

- [How to Fix OpenClaw OOM Errors](/guides/openclaw-oom-fix) - VRAM optimization tips

- [DeepSeek R1 Optimization Guide](/guides/deepseek-r1-optimization) - Context window and performance tuning

---

> **Found this helpful?** For production deployments with better VRAM and stability, consider **High-Performance VPS Setup**.
